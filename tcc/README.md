# Generating Temporally Cycle-Consistent Tracking Points with OpenCV

This part of the code aims to create a dataset of tracking points using OpenCV's optical flow algorithms. 
The dataset is generated by tracking points in a video segment forwards and then backwards in time to ensure consistency.

## Folder Structure
```
configs/
    config.yaml                     # Example config for scripts/gen_point_dataset.py
scripts/
    apply_tcc_videos.py             # Script to generate a dataset of patches using tcc
utils/
    utils.py                        # Functions for general utility
    bboxes.py                       # Functions for handling bounding boxes

requirements.txt                    # Required Python packages
README.md                           # You are here
```

## Tutorial

1. **Install dependencies**:
    
    This part can be executed in a different Python environment to avoid potential compatibility issues.

    ```bash
    pip install -r requirements.txt
    ```

2. **Set up the configuration**:

    Modify the `configs/config.yaml` file to specify the input video folder path, and any other parameters needed. The following parameters are available:

    ```yaml
    video_path: ./video_folder  # Path to the folder containing the video files to process
    zarr_path: ./dataset.zarr   # Path to save the resulting zarr dataset
    pkl_save_path: ./patch_pkls # Path to save the isolated patches in pkl format
    tracking_window: 10        # Number of frames for which to track points. Set it to null to track for the entire video
    sample_overlap: 9          # Overlap between frames of consecutive samples
    logs_path: ./logs/         # Path to save logs, i.e. tracking visualizations and metrics
    num_viz_per_video: 3       # Number of visualizations to save per video

    feature_params:            # Parameters for feature detection which define tracking points
        maxCorners: 500        # Maximum number of points (corners) to detect
        qualityLevel: 0.01     # Minimum quality level for corner detection
        minDistance: 40        # Minimum pixel distance between detected corners
        blockSize: 7           # Size of an average block for computing a derivative covariation matrix over each pixel neighborhood
                               # See cv::cornerEigenValsAndVecs
    lk_params:                 # Parameters for Lucas-Kanade optical flow
        winSize: [32, 32]      # Size of the search window at each pyramid level
        maxLevel: 2            # Maximum pyramid level number
        criteria:              # Criteria for termination of the iterative refinement process
            epsilon: 0.03 
            max_iter: 10

    consistency_threshold: 20  # Threshold for consistency check between forward and backward optical flow
    jpegxl_compression: True   # Whether to compress the visualizations with JPEG-XL or not. 
                               # If False, default (faster) compression is used which results in ~4x larger dataset size.

    bboxes:                   # Paratemers for bounding boxes generated from pairs of tracking points
        min_init_dim: 32      # Minimum Height/Width of the bounding box in the initial frame
        max_init_dim: 64      # Maximum Height/Width of the bounding box in the initial frame
        min_dim_all_frames: 4 # Minimum Height/Width of the tracked bounding box in all frames
        padding_pixels: 4     # Padding around the bounding box so that there will not be adjacent or overlapping bounding boxes
    ```

3. **Generate the dataset**:


    ### Create patch dataset with 4-point bounding boxes

    Run the `apply_tcc_videos.py` script to generate the dataset:

    ```bash
    cd scripts
    python apply_tcc_videos.py -c ../configs/config.yaml 
    ```

    ### Arguments

    * `'-sv/--save_vid'` (optional): Create also videos of the patches in each sample
    * `'-c/--config'` (required): Path to the configuration file

    ### Outputs

    The script will process all video files in the specified `video_path` folder and generate pickle files that correspond to the videos contained in the folder, with the following structure:

    ```
    │    logs_path/
    ├── video_viz/
    │   ├── viz_<video_name>/
    │   │   ├── sample_<sample_idx>_all.mp4
    │   │   ├── sample_<sample_idx>_bboxes.mp4
    │   │   ├── sample_<sample_idx>_frame_0.png
    │   │   ├── sample_<sample_idx>_frame_<T/2>.png
    │   │   ├── sample_<sample_idx>_frame_<T-1>.png
    │   │   ├── sample_<sample_idx>_patches/
    │   │   │   ├── patch_<bbox_id>_frame_<t>.png
    │   │   │   └── ...
    │   │   ├── sample_<sample_idx>_concat_patches/
    │   │   │   ├── bboxes_frame_<t>.png
    │   │   │   └── ...
    │   │   └── ...
    │   └── ...
    ├── patches_pkl/
    │   ├── <video_name>_window_<sample_idx>_patches.pkl
    │   └── ...
    ```

    **Description of Generated Files** 
    
    * sample_<sample_idx>_all.mp4: A visualization of the full video with all detected and tracked bounding boxes overlaid as green quadrilaterals.
    * sample_<sample_idx>_bboxes.mp4: A grid video containing all tracked patches (cropped from their bounding boxes) arranged in a grid layout. Each cell in the grid corresponds to a tracked region from the original video.
    * sample_<sample_idx>_frame_<\t>.png: Keyframe snapshots (beginning, middle, and end of the video) showing all tracked bounding boxes on the original frame.
    * sample_<sample_idx>_patches/: Contains all individual patch crops for each bounding box at different timesteps, stored as images. Each file is named as patch_<bbox_id>_frame_<\t>.png.
    * sample_<sample_idx>_concat_patches/: Contains concatenated grid images (bboxes_frame_<\t>.png) showing all patches at a given frame.
    * <video_name>_window_<sample_idx>_patches.pkl: A serialized (pickle) file that stores the extracted patches for each tracked bounding box. The pickle structure is a dictionary where:

    ```
    {
    bbox_id_0: [patch_t0, patch_t1, patch_t2, ...],
    bbox_id_1: [patch_t0, patch_t1, patch_t2, ...],
    ...
    }
    ```
    Each patch is stored as a NumPy array of shape (H, W, 3) in RGB format.

    ### Notes

    * The naming pattern window_<sample_idx> corresponds to the temporal window used during processing.
    * Videos that do not contain valid bounding boxes or consistent trajectories will be automatically skipped.
    * If pkl_save_path is not provided in the configuration, the script will skip saving .pkl files.
